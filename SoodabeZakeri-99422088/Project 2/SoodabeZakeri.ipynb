{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soodabe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CYjjpT_hYYP"
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy import stats\n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2L4MtaVd4P"
      },
      "source": [
        "# 1-A : \n",
        "there are noisy records in the dataset and they are shown as circles in the box chart below. these noisy records are then deleted using Z-score as followed : \n",
        "> `df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTmFxXYPkk8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "73163ded-015b-400a-9bf0-460650dd9150"
      },
      "source": [
        "df = pd.read_csv(\"heart.csv\")\n",
        "boxplot = df.boxplot(column=['age', 'trestbps', 'chol','thalach','oldpeak'])\n",
        "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21EmKzz1zI5X"
      },
      "source": [
        "# 1-B:\n",
        " data points are not equally distributed in the two target classes and therefore the dataset is not fully balanced. due to this problem, we will not be able to use predictive accuracy as an evaluation method because the model's prediction would be biased towards the class with more data points.\n",
        "\n",
        "\n",
        "there are 2 common solutions for this issue : \n",
        "\n",
        "\n",
        "1.   sampling methods : these methods include **oversampling** and **undersampling**.\n",
        "oversampling involves generating new data points for the minority class, and undersampling involves removing data points from the majority class\n",
        "2.   Cost-Sensitive Learning : there are 2 approaches for cost-sensitive learning, Upweighting and Down-weighting. Upweighting is analogous to over-sampling and works by increasing the weight of one of the classes keeping the weight of the other class at one. Down-weighting is analogous to under-sampling and works by decreasing the weight of one of the classes keeping the weight of the other class at one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ecaZvxtW0op",
        "outputId": "21897deb-6afd-4916-da07-59c67315af72"
      },
      "source": [
        "print(\"target 0 : \",df[df.target == 0].shape[0])\n",
        "print(\"target 1 : \",df[df.target == 1].shape[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target 0 :  129\n",
            "target 1 :  158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAWM6Nyl8pan"
      },
      "source": [
        "# 2 : \n",
        "first, the input and the output are separated, then the corresponding input and output for train and test are derived from the main dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SljnXxLC7h_A"
      },
      "source": [
        "output = df['target']\n",
        "input = df.drop(['target'],axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(input, output, test_size=0.2, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMvy-4WF9sPL"
      },
      "source": [
        "# 3 :\n",
        "In statistics and probability theory, the Bayes’ theorem (also known as the Bayes’ rule) is a mathematical formula used to determine the conditional probability of events. Essentially, the Bayes’ theorem describes the probability of an event based on prior knowledge of the conditions that might be relevant to the event.\n",
        "\n",
        "P(A|B) =  (P(A).P(B|A)) / P(B)\n",
        "\n",
        "*   P(A|B) – the probability of event A occurring, given event B has occurred\n",
        "*   P(B|A) – the probability of event B occurring, given event A has occurred\n",
        "*   P(A) – the probability of event A\n",
        "*   P(B) – the probability of event B\n",
        "\n",
        "## Gaussian Naive Bayes : \n",
        "In Gaussian Naive Bayes, continuous values associated with each feature are assumed to be distributed according to a Gaussian distribution.\n",
        "\n",
        "## Multinomial Naive Bayes : \n",
        "Feature vectors represent the frequencies with which certain events have been generated by a multinomial distribution.\n",
        "\n",
        "## Bernoulli Naive Bayes : \n",
        "In the multivariate Bernoulli event model, features are independent booleans (binary variables) describing inputs. Like the multinomial model, this model is popular for document classification tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAciRtCwKQvF"
      },
      "source": [
        "# 4 : \n",
        "the gaussian naive bayes model is defined as a class :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vudvqM0LB0kY",
        "outputId": "4e08575c-ed29-4e32-d1eb-47a822412b96"
      },
      "source": [
        "X_train = X_train[['chol','trestbps','thalach']]\n",
        "X_test = X_test[['chol','trestbps','thalach']]\n",
        "class GaussianNaiveBayesClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def fit(self, X, y):\n",
        "        X, y = check_X_y(X, y)\n",
        "        self.priors_ = np.bincount(y) / len(y)\n",
        "        self.n_classes_ = np.max(y) + 1\n",
        "        \n",
        "        self.means_ = np.array([X[np.where(y==i)].mean(axis=0) for i in range(self.n_classes_)])\n",
        "        self.stds_ = np.array([X[np.where(y==i)].std(axis=0) for i in range(self.n_classes_)])\n",
        "        \n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "        \n",
        "        res = []\n",
        "        for i in range(len(X)):\n",
        "            probas = []\n",
        "            for j in range(self.n_classes_):\n",
        "                probas.append((1/np.sqrt(2*np.pi*self.stds_[j]**2)*np.exp(-0.5*((X[i]-self.means_[j])/self.stds_[j])**2)).prod()*self.priors_[j])\n",
        "            probas = np.array(probas)\n",
        "            res.append(probas / probas.sum())\n",
        "            \n",
        "        \n",
        "        return np.array(res)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "        \n",
        "        res = self.predict_proba(X)\n",
        "        \n",
        "        return res.argmax(axis=1)\n",
        "\n",
        "\n",
        "my_gauss = GaussianNaiveBayesClassifier()\n",
        "my_gauss.fit(X_train, y_train)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNaiveBayesClassifier()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc0_Zkk_KUhd"
      },
      "source": [
        "# 5 : \n",
        "using the model's prediction and the true labels, scores are calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nhSVBbTKViN",
        "outputId": "057555ee-5614-4c11-e5f4-82844aff07f0"
      },
      "source": [
        "def argmax(p):\n",
        "  if p[0] > p[1] :\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "predicted = np.zeros(len(y_test))\n",
        "predicted = [argmax(p) for p in my_gauss.predict_proba(X_test)]\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.7070707070707072\n",
            "Precision :  0.7117117117117118\n",
            "Recall :  0.7043478260869566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYK-i1hHLxml"
      },
      "source": [
        "# 6 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7oFpHDWLx9X",
        "outputId": "02cd333e-14fa-479e-a6e7-1d15d174fa91"
      },
      "source": [
        "clf = GaussianNB()\n",
        "clf.fit(X_train,y_train)\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.7070707070707072\n",
            "Precision :  0.7117117117117118\n",
            "Recall :  0.7043478260869566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu5Z856aNITL"
      },
      "source": [
        "# 7\n",
        "the results of the custom model and the gaussianNB were identical, therefore the scores are also identical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB6MOimSNSw7"
      },
      "source": [
        "# 8 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CliphU4hNR_l",
        "outputId": "30f1527e-9106-4d8a-aca8-b67ad3e4e286"
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train,y_train)\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.6996649406031068\n",
            "Precision :  0.6983173076923077\n",
            "Recall :  0.7049689440993789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw8lOI6rOQw9"
      },
      "source": [
        "# 9\n",
        "the model's scores were better while using the RBF kernel.\n",
        "using different kernels in SVM models, allow us to add non-linearity to the model's prediction. there is no exact rule on how to choose the right kernel that would apply to all the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTbKvcf5OQ_i",
        "outputId": "16f14b6e-a04a-4890-c9d2-d53c1e9539f9"
      },
      "source": [
        "clf_rbf = make_pipeline(StandardScaler(), SVC(gamma='auto',kernel='rbf'))\n",
        "clf_rbf.fit(X_train,y_train)\n",
        "predicted_rbf = clf_rbf.predict(X_test)\n",
        "\n",
        "print(\"RBF kernel : \")\n",
        "print(\"F1-score : \",f1_score(y_test, predicted_rbf, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted_rbf, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted_rbf, average='macro'))\n",
        "\n",
        "\n",
        "clf_sigmoid = make_pipeline(StandardScaler(), SVC(gamma='auto',kernel='sigmoid'))\n",
        "clf_sigmoid.fit(X_train,y_train)\n",
        "predicted_sigmoid = clf_sigmoid.predict(X_test)\n",
        "\n",
        "print(\"\\nSigmoid kernel : \")\n",
        "print(\"F1-score : \",f1_score(y_test, predicted_sigmoid, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted_sigmoid, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted_sigmoid, average='macro'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RBF kernel : \n",
            "F1-score :  0.6996649406031068\n",
            "Precision :  0.6983173076923077\n",
            "Recall :  0.7049689440993789\n",
            "\n",
            "Sigmoid kernel : \n",
            "F1-score :  0.6289978678038379\n",
            "Precision :  0.6286057692307692\n",
            "Recall :  0.632919254658385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-3eALNnQIHN"
      },
      "source": [
        "# 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW9cykaBQJLm",
        "outputId": "50462bab-0a69-4b01-d1c5-a7ee9e1dc8e0"
      },
      "source": [
        "output = df['target']\n",
        "input = df.drop(['target'],axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(input, output, test_size=0.2, random_state=42)\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train,y_train)\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.7867647058823529\n",
            "Precision :  0.7842424242424242\n",
            "Recall :  0.791304347826087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg_VhDyhQ1VF"
      },
      "source": [
        "# 11\n",
        "we used all datapoints to assess cross validation scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3muyeIjSQ1ow",
        "outputId": "0ae37128-e6d1-4da2-ef55-db3e076bfb52"
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(X_train,y_train)\n",
        "scores = cross_val_score(clf, input, output, cv=5)\n",
        "print(scores)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.81034483 0.89655172 0.80701754 0.84210526 0.73684211]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47X1YHwhSbRu"
      },
      "source": [
        "# 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAdnyo8dSbbt",
        "outputId": "656d9d28-d04c-405a-e55a-c893bef8856d"
      },
      "source": [
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)\n",
        "predicted = neigh.predict(X_test)\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.6535244922341696\n",
            "Precision :  0.6630824372759856\n",
            "Recall :  0.6695652173913043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGVRGt9ySwAi"
      },
      "source": [
        "# 13\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kpRBRzHS1zx"
      },
      "source": [
        "# 14\n",
        "the scores decreased slightly when we used only 3 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAHu077ZS2UP",
        "outputId": "9f7e5ba3-8728-4e8a-8e95-609e4b9e31a7"
      },
      "source": [
        "X_train = X_train[['chol','trestbps','thalach']]\n",
        "X_test = X_test[['chol','trestbps','thalach']]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train)\n",
        "predicted = neigh.predict(X_test)\n",
        "\n",
        "print(\"F1-score : \",f1_score(y_test, predicted, average='macro'))\n",
        "print(\"Precision : \",precision_score(y_test, predicted, average='macro'))\n",
        "print(\"Recall : \",recall_score(y_test, predicted, average='macro'))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score :  0.6551724137931034\n",
            "Precision :  0.684472049689441\n",
            "Recall :  0.684472049689441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ2-jIe-fRS6"
      },
      "source": [
        "# 15\n",
        "Difference between parametric and nonparametric test is that the parametric test relies on statistical distributions in data whereas nonparametric do not depend on any distribution. Non-parametric does not make any assumptions and measures the central tendency with the median value. \n",
        "Nonparametric are valid in a broader range of situations (fewer conditions of validity).\n",
        "A parametric test is more able to lead to a rejection of H0. Most of the time, the p-value associated to a parametric test will be lower than the p-value associated to a nonparametric equivalent that is run on the same data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z77RsP_xfVZ3"
      },
      "source": [
        "# 16\n",
        "Matthew’s correlation coefficient is a tool for model evaluation. It measures the differences between actual values and predicted values and is equivalent to the chi-square statistic  for a 2 x 2 contingency table .\n",
        "Matthew’s correlation coefficient is the best metric for binary classification problems.\n",
        "  "
      ]
    }
  ]
}